{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "# noinspection PyPep8Naming\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from CharacterGenerator import generate_data_set\n",
    "import os\n",
    "\n",
    "OUT_DIR = f'{os.path.basename(__file__)[:-3]}_out'\n",
    "if not os.path.isdir(OUT_DIR):\n",
    "    os.mkdir(OUT_DIR)\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    K.set_image_dim_ordering(\"th\")\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), class_names = generate_data_set(train_repeat=1000, test_repeat=500,\n",
    "                                                                      out_dir=OUT_DIR)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:] == i)[0]\n",
    "    features_idx = x_train[idx, ::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = np.transpose(features_idx[img_num, ::], (1, 2, 0))\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im)\n",
    "plt.show()\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "# Define Model\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, nesterov=True)\n",
    "\n",
    "    # Train model\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "cnn_n = base_model()\n",
    "cnn_n.summary()\n",
    "\n",
    "# Visualising model structure\n",
    "\n",
    "sequential_model_to_ascii_printout(cnn_n)\n",
    "\n",
    "# Fit model\n",
    "\n",
    "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "cnn_n.save(\"Task2.h5\")\n",
    "\n",
    "# Plots for training and testing process: loss and accuracy\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(cnn.history['acc'], 'r')\n",
    "plt.plot(cnn.history['val_acc'], 'g')\n",
    "plt.xticks(np.arange(0, 11, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "plt.legend(['train', 'validation'])\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(cnn.history['loss'], 'r')\n",
    "plt.plot(cnn.history['val_loss'], 'g')\n",
    "plt.xticks(np.arange(0, 11, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()\n",
    "\n",
    "scores = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "\n",
    "# Confusion matrix result\n",
    "\n",
    "Y_pred = cnn_n.predict(x_test, verbose=2)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "for ix in range(10):\n",
    "    print(ix, confusion_matrix(np.argmax(y_test, axis=1), y_pred)[ix].sum())\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Visualizing of confusion matrix\n",
    "\n",
    "df_cm = pd.DataFrame(cm, range(10),\n",
    "                     range(10))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12})  # font size\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}